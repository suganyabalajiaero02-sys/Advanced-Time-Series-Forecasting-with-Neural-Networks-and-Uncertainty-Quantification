{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a35e87-d565-4998-882e-37ea35c28bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Advanced Time Series Forecasting with Neural Networks\n",
    "# Probabilistic Forecasting using Quantile Regression LSTM\n",
    "# ================================================================\n",
    "\n",
    "# ========================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# ========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 2. GENERATE MULTIVARIATE TIME SERIES (5 correlated features)\n",
    "# ========================\n",
    "np.random.seed(42)\n",
    "T = 1000\n",
    "t = np.arange(T)\n",
    "\n",
    "season = 2*np.sin(2*np.pi*t/50)  # seasonal\n",
    "regime = np.where(t < 600, 0.02*t, 0.02*600 + 0.05*(t-600))  # nonlinear regime shift\n",
    "\n",
    "# 5Ã—5 covariance matrix\n",
    "cov = np.array([\n",
    "    [1.0, 0.7, 0.5, 0.4, 0.3],\n",
    "    [0.7, 1.0, 0.6, 0.5, 0.2],\n",
    "    [0.5, 0.6, 1.0, 0.4, 0.4],\n",
    "    [0.4, 0.5, 0.4, 1.0, 0.6],\n",
    "    [0.3, 0.2, 0.4, 0.6, 1.0]\n",
    "])\n",
    "noise = np.random.multivariate_normal(np.zeros(5), cov, size=T)\n",
    "\n",
    "X = np.zeros((T, 5))\n",
    "for i in range(5):\n",
    "    X[:,i] = 0.5*season + 0.3*regime + noise[:,i]\n",
    "\n",
    "df = pd.DataFrame(X, columns=[f\"feat_{i+1}\" for i in range(5)])\n",
    "df[\"target\"] = df[\"feat_1\"].shift(-1)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 3. TRAIN/TEST SPLIT + SCALING\n",
    "# ========================\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(df.values)\n",
    "\n",
    "train_size = 800\n",
    "train_data = scaled[:train_size]\n",
    "test_data = scaled[train_size:]\n",
    "\n",
    "WINDOW = 20\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 4. PYTORCH DATASET\n",
    "# ========================\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, data, window):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data)-window):\n",
    "            X.append(data[i:i+window,:5])\n",
    "            y.append(data[i+window,5])\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = SeqDataset(train_data, WINDOW)\n",
    "test_ds = SeqDataset(test_data, WINDOW)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 5. PROBABILISTIC LSTM (Quantile Regression)\n",
    "# ========================\n",
    "class QuantileLSTM(nn.Module):\n",
    "    def __init__(self, n_features, hidden=64, n_quantiles=3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(n_features, hidden, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden, n_quantiles)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out,_ = self.lstm(x)\n",
    "        return self.fc(out[:,-1,:])\n",
    "\n",
    "def pinball(y_true, y_pred, q):\n",
    "    err = y_true - y_pred\n",
    "    return torch.max((q-1)*err, q*err).mean()\n",
    "\n",
    "quantiles = torch.tensor([0.1, 0.5, 0.9])\n",
    "model_q = QuantileLSTM(5)\n",
    "opt_q = torch.optim.Adam(model_q.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 6. TRAIN QUANTILE MODEL\n",
    "# ========================\n",
    "print(\"\\nTraining Quantile_LSTM...\")\n",
    "for epoch in range(30):\n",
    "    model_q.train()\n",
    "    loss_total = 0\n",
    "    for Xb, yb in train_loader:\n",
    "        opt_q.zero_grad()\n",
    "        preds = model_q(Xb)\n",
    "        loss = sum(pinball(yb, preds[:,i], quantiles[i]) for i in range(3))\n",
    "        loss.backward()\n",
    "        opt_q.step()\n",
    "        loss_total += loss.item()\n",
    "    print(f\"Epoch {epoch+1:02d}, Loss={loss_total:.4f}\")\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 7. BASELINE MODEL (Point LSTM)\n",
    "# ========================\n",
    "class PointLSTM(nn.Module):\n",
    "    def __init__(self, n_features, hidden=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(n_features, hidden, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out,_ = self.lstm(x)\n",
    "        return self.fc(out[:,-1,:]).squeeze()\n",
    "\n",
    "model_base = PointLSTM(5)\n",
    "opt_b = torch.optim.Adam(model_base.parameters(), lr=1e-3)\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "print(\"\\nTraining Baseline LSTM...\")\n",
    "for epoch in range(30):\n",
    "    model_base.train()\n",
    "    epoch_loss = 0\n",
    "    for Xb, yb in train_loader:\n",
    "        opt_b.zero_grad()\n",
    "        pred = model_base(Xb)\n",
    "        loss = mse_loss(pred, yb)\n",
    "        loss.backward()\n",
    "        opt_b.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1:02d}, Loss={epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 8. EVALUATION FUNCTIONS\n",
    "# ========================\n",
    "def evaluate_quantile(model, loader):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in loader:\n",
    "            p = model(Xb)\n",
    "            preds.append(p.numpy())\n",
    "            trues.append(yb.numpy())\n",
    "    return np.concatenate(preds), np.concatenate(trues)\n",
    "\n",
    "def evaluate_point(model, loader):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in loader:\n",
    "            p = model(Xb)\n",
    "            preds.append(p.numpy())\n",
    "            trues.append(yb.numpy())\n",
    "    return np.concatenate(preds), np.concatenate(trues)\n",
    "\n",
    "def coverage(preds, trues):\n",
    "    L = preds[:,0]\n",
    "    H = preds[:,2]\n",
    "    return np.mean((trues >= L) & (trues <= H))\n",
    "\n",
    "def interval_width(preds):\n",
    "    return np.mean(preds[:,2] - preds[:,0])\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 9. RUN EVALUATION\n",
    "# ========================\n",
    "preds_q, trues = evaluate_quantile(model_q, test_loader)\n",
    "preds_b, trues_b = evaluate_point(model_base, test_loader)\n",
    "\n",
    "rmse_q = mean_squared_error(trues, preds_q[:,1], squared=False)\n",
    "mae_q = mean_absolute_error(trues, preds_q[:,1])\n",
    "\n",
    "rmse_b = mean_squared_error(trues_b, preds_b, squared=False)\n",
    "mae_b = mean_absolute_error(trues_b, preds_b)\n",
    "\n",
    "cov80 = coverage(preds_q, trues)\n",
    "iw = interval_width(preds_q)\n",
    "\n",
    "print(\"\\n==================== RESULTS ====================\")\n",
    "print(f\"Baseline LSTM: RMSE={rmse_b:.4f}, MAE={mae_b:.4f}\")\n",
    "print(f\"Quantile LSTM: RMSE={rmse_q:.4f}, MAE={mae_q:.4f}\")\n",
    "print(f\"Coverage (80% interval) = {cov80:.4f}\")\n",
    "print(f\"Average interval width = {iw:.4f}\")\n",
    "print(\"=================================================\")\n",
    "\n",
    "\n",
    "# ========================\n",
    "# 10. PLOTS\n",
    "# ========================\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(trues[:200], label=\"True\", color=\"black\")\n",
    "plt.plot(preds_q[:200,1], label=\"Median Forecast\", color=\"blue\")\n",
    "plt.fill_between(np.arange(200), preds_q[:200,0], preds_q[:200,2],\n",
    "                 color=\"lightblue\", alpha=0.5, label=\"80% interval\")\n",
    "plt.title(\"Probabilistic Forecast (First 200 steps)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
